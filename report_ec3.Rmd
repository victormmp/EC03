---
title: 'Estudo de Caso 3: Planejamento e Análise de Experimentos'
author: "Matheus Marzochi, Mayra Mota, Rafael Ramos e Victor Magalhães"
date: "11 de Novembro de 2019"
output:
  pdf_document:
    fig_caption: yes
  html_document:
    df_print: paged
---

```{r setup,results='hide',warning=FALSE,echo=FALSE, include=FALSE}
# A few initial definitions just to make sure all required packages are installed. Change as needed.
# NOTE: It may echo some weird messages to the PDF on the first compile (package installation messages). Run twice and the problem will (hopefully) go away.

rm(list=ls())

if (!require(ggplot2, quietly = TRUE)){
      install.packages("ggplot2")
      }
if (!require(devtools, quietly = TRUE)){
      install.packages("devtools")
      }
if (!require(broom, quietly = TRUE)){
       devtools::install_github("dgrtwo/broom")
 }

if (!require(ExpDE, quietly = TRUE)){
      install.packages("ExpDE")
}

if (!require(stats, quietly=TRUE)) {
      install.packages("stats")
}

if (!require(boot, quietly=TRUE)) {
      install.packages("boot")
}

if (!require(ggpubr, quietly=TRUE)) {
      install.packages("ggpubr")
}

# knitr::opts_chunk$set(fig.width=6, fig.height=4) 

if (!require(GGally, quietly = TRUE)){
      install.packages("GGally")
}

if (!require(car, quietly = TRUE)){
      install.packages("car")
}

if (!require(samplesize, quietly = TRUE)){
      install.packages("samplesize")
}

if (!require(pwr, quietly = TRUE)){
      install.packages("pwr")
}
if (!require(simpleboot, quietly = TRUE)){
  install.packages("simpleboot")
}
if (!require(dplyr, quietly = TRUE)){
  install.packages("dplyr")
}
if (!require(effsize, quietly = TRUE)){
  install.packages("effsize")
}
if (!require(smoof, quietly = TRUE)) {
  install.packages(smoof)
}
if (!require(pracma, quietly = TRUE)) {
  install.packages(pracma)
}


suppressPackageStartupMessages(library(ExpDE))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(stats))
suppressPackageStartupMessages(library(boot))
suppressPackageStartupMessages(library(ggpubr))
suppressPackageStartupMessages(library(smoof))
suppressPackageStartupMessages(library(pracma))
suppressPackageStartupMessages(library(CAISEr))

```
## Resumo

O objetivo deste estudo de caso é investigar como modificações de hiperparâmetros de um algoritmo de otimização baseado em evolução diferencial influenciam em seu desempenho, em diferentes cenários de execução. Os algoritmose serão testados  partir de funções de Rosenbrook, de dimensões entre 2 e 150. 

## Papéis Desempenhados

A divisão de tarefas no grupo segue a descrição da *Declaração de Políticas de Equipe*. Estando aqui organizada da seguinte forma:

 - Matheus: Verificador
 - Mayra: Monitora
 - Rafael: Coordenador
 - Victor: Revisor

## Planejamento do Experimento


### Descrição do Problema

O problema analisado tem por objetivo comparar o desempenho de duas configurações de um algoritmo de otimização baseada em evolução diferencial, na resolução do problema de ótimo em funções de Rosenbrook. As funções podem possuir dimensões que variam entre 2 e 150. A hipótese nula é a de que o desempenho dos dois algoritmos permanece o mesma independente da configuração, e a hipótese que está sendo testada é a de que existe uma diferenção de desempenho entre elas.

Para avaliar o desempenho de cada um dos algoritmos, seus desempenhos sob diferentes dimensões da função de Rosenbrook são levados em consideração, a partir de testes pareados. Testes pareados constituem uma parte de testes blocados, onde distribuições são comparadas caso a caso, agrupadas em blocos, com o objetivo de diminuir efeitos que não estejam relacionados com os parâmetros em teste. O valor de performance $y$ para cara algoritmo $i$ em cada instância $j$ é dado a partir da fórmula:

$$
y_{ij} = \mu + \tau_i + \beta_j + \epsilon_{ij}
$$

onde $\mu$ corresponde à média geral de todas as amostras, $\tau_i$ corresponde o efeito do i-ésimo algoritmo, $\beta_j$ representa , e $\epsilon_{ij}$ representa um erro randômico com média nula e independentemente distribuídos, de variância $\sigma^2$. 

O que queremos testar é a equivalência dos parâmetros sob teste para cada algoritmo, ou seja, $y_i$. Seja $y_i$ definido como:

$$
  y_i = \sum^{n}_{j = 1} y_{ij} \\
  \overline{y_i} = \frac{y_i}{n}
$$

onde $n$ equivale ao total de instâncias (blocos). A hipótese nula é:

$$
H_0: y_1 = y_2 = ... = y_a
$$

onde a equivale ao total de algoritmos sendo comparados, o que no problema em questão são 2. Como o que difere cada parâmetro $y_i$ é o valor da influência do algoritmo i, dizer que a hipótese nula é que os parâmetros $y_i$ são iguais equivale a deizer que 

$$
H_0: \tau_1 = \tau_2 = ... = \tau_a = 0
$$

o que indica não haver influência do algoritmo nos parâmetros das execuções, e a definição do mesmo passa a ser portanto apenas a média global acrescida de um erro $\epsilon_{ij}$. Isto equivale a dizer que todas as observações foram retiradas de uma distribuição normal com média $\mu$ e variância $\sigma^2$. A hipótese em teste, é:

$$
H_1: \tau_i = 0 
$$

para pelo menos algum valor de i.

Para este trabalho, deseja-se saber se existe alguma diferença no desempenho médio do algoritmo quando carregado com diferentes configurações. O parâmetro utilizado foi baseado na diferença do desempenho médio das configurações 1 e 2, por tratar-se de uma análise pareada.  Se as duas configurações apresentarem o mesmo desempenho, a diferença das médias de cada população amostrada será zero. Se uma configuração tiver o desempenho superior, o valor não será nulo. Desta forma, sendo $\mu= \mu_1 - \mu_2$, o teste deve possuir as seguintes hipóteses:
$$
\begin{cases} H_0: \mu= 0 & \\ 
H_1: \mu\neq 0 \end{cases}
$$

### Execução do Experimento

Como deseja-se avaliar o desempenho das duas configurações de algoritmos sob diferentes dimensões de problema, serão realizados testes pareados. Cada observação do teste corresponde a uma dimensão do problema de Rosenbrook. Considerando as métricas para o teste estabelecidas anteriormente, o número de instâncias para o teste pareado deverá ser, no  mínimo, 34 amostras, como o cálculo a seguir demonstra.

```{r num_amostras, echo=TRUE}
result <- power.t.test(delta=0.5,
             sig.level=0.05,
             power=0.8,
             type='paired',
             alternative='two.sided')
print(result)
```



## Coleta dos Dados

Como, a princípio, não podemos assumir normalidade dos dados coletados, para saber a quantidade de instâncias a ser utilizada, fizemos o cálculo considerando o uso do teste de Wilcoxon.

```{r numero_de_instancias, eval=T, echo=T}
Ncalc <- calc_instances(
    power=0.8,
    d=0.5,
    sig.level=0.05,
    alternative.side='two.sided',
    test='wilcoxon',
    ncomparisons=1
)
print(Ncalc$ninstances)
```

O que nos indica o uso de, no mínimo, 45 instâncias. A partir de uma rotina de coleta, geramos arquivos csv com os resultados das execuções dos algoritmos.

```{r coleta_dados, echo=TRUE, eval=FALSE}
n_instancias <- 45

dimensions <- sample(seq(2, 150), n_instancias)

out_dim.conf1 = data.frame(matrix(ncol = 2, nrow = 0))
colnames(out_dim.conf1) <- c("dim", "best")
out_dim.conf2 = data.frame(matrix(ncol = 2, nrow = 0))
colnames(out_dim.conf2) <- c("dim", "best")

count.dim <- 1
for (d in dimensions){

    dim <- ceil(d)
    
    for (r in 1:30) {
        
    
        cat("\nBuilding dimension ", dim)
    
        fn <- function(X){
            if(!is.matrix(X)) X <- matrix(X, nrow = 1) 
            Y <- apply(X, MARGIN = 1,
                       FUN = smoof::makeRosenbrockFunction(dimensions = dim))
            return(Y)
        }
        selpars <- list(name = "selection_standard")
        stopcrit <- list(names = "stop_maxeval", maxevals = 5000*dim, maxiter = 100*dim)
        probpars <- list(name = "fn", xmin = rep(-5, dim), xmax = rep(10, dim))
        popsize = 5 * dim
    
        ## Config 1
        recpars1 <- list(name = "recombination_arith")
        mutpars1 <- list(name = "mutation_rand", f = 4)
        ## Config 2
        recpars2 <- list(name = "recombination_bin", cr = 0.7)
        mutpars2 <- list(name = "mutation_best", f = 3)
    
        out <- ExpDE(mutpars = mutpars1,
                     recpars = recpars1,
                     popsize = popsize,
                     selpars = selpars,
                     stopcrit = stopcrit,
                     probpars = probpars,
                     showpars = list(show.iters = "dots", showevery = 20))
        de <- list("dim"=dim, "best"=out$Fbest, "repetition"=r)
        out_dim.conf1 <- rbind(out_dim.conf1,de, stringsAsFactors=FALSE)
    
        out <- ExpDE(mutpars = mutpars2,
                     recpars = recpars2,
                     popsize = popsize,
                     selpars = selpars,
                     stopcrit = stopcrit,
                     probpars = probpars,
                     showpars = list(show.iters = "dots", showevery = 20))
        de <- list("dim"=dim, "best"=out$Fbest, "repetition"=r)
        out_dim.conf2 <- rbind(out_dim.conf2,de, stringsAsFactors=FALSE)
    
    }

    count.dim <- count.dim + 1
}

write.csv(out_dim.conf1, 'conf_1.csv', row.names=FALSE)
write.csv(out_dim.conf2, 'conf_2.csv', row.names=FALSE)
```

Ao final, temos um conjunto com 45 instâncias correspondentes a ordens do algoritmo de Rosenbrook, com 30 amostras em cada um.

## Análise Exploratória dos Dados

Avaliando as amostras contidas em cada instância, uma análise de normalidade foi realizada:

```{r teste_normalidade, eval=F, echo=T}

conf_1 <- read.csv(file='conf_1.csv', sep=',')
conf_2<- read.csv(file='conf_2.csv', sep=',')

dataConf1 <- matrix(as.numeric(unlist(conf_1[,2])),nrow=nrow(conf_1))
dataConf2 <- matrix(as.numeric(unlist(conf_2[,2])),nrow=nrow(conf_2))

difs <- c()
all_conf_1 <- c()
all_conf_2 <- c()
for (i  in seq(1, nrow(dataConf1), 10)) {
    
    samples1 <- as.vector(dataConf1[i:(i+9),])
    samples2 <- as.vector(dataConf2[i:(i+9),])
    all_conf_1 <- c(all_conf_1, mean(samples1))
    all_conf_2 <- c(all_conf_2, mean(samples2))
    dif <- mean(samples1) - mean(samples2)
    difs <- c(difs, dif)
}
```

```{r teste_real, echo=F, eval=T}
conf_1 <- read.csv(file='conf_45_1_Matheus.csv', sep=',')
conf_2<- read.csv(file='conf_45_2_Matheus.csv', sep=',')

dataConf1 <- matrix(as.numeric(unlist(conf_1[,2])),nrow=nrow(conf_1))
dataConf2 <- matrix(as.numeric(unlist(conf_2[,2])),nrow=nrow(conf_2))

conf_1 <- read.csv(file='conf_45_1_Victor.csv', sep=',')
conf_2<- read.csv(file='conf_45_2_Victor.csv', sep=',')

dataConf1V <- matrix(as.numeric(unlist(conf_1[,2])),nrow=nrow(conf_1))
dataConf2V <- matrix(as.numeric(unlist(conf_2[,2])),nrow=nrow(conf_2))

dataConf1 <- cbind(dataConf1, dataConf1V)
dataConf2 <- cbind(dataConf2, dataConf2V)

difs <- c()
all_conf_1 <- c()
all_conf_2 <- c()
for (i  in seq(1, nrow(dataConf1), 10)) {

    samples1 <- as.vector(dataConf1[i:(i+9),])
    samples2 <- as.vector(dataConf2[i:(i+9),])
    all_conf_1 <- c(all_conf_1, mean(samples1))
    all_conf_2 <- c(all_conf_2, mean(samples2))
    dif <- mean(samples1) - mean(samples2)
    difs <- c(difs, dif)
}

shapiro.test(difs)

```

De acordo com o teste de Shapiro-Wilk, o p-valor para a diferença foi de $0.006$, abaixo da incerteza de 0.05, o que é um indício de que a distribuição dos dados não é normal. 

O boxplot para as diferenças, como pode ser visto a seguir, mostra que existe uma assimetria nos dados, o que corrobora com a hipótese de não-normalidade.

```{r boxplot, echo=F, fig=T, fig.align='center', fig.cap='Box plot para as diferenças das médias.'}
boxplot(difs)
```





Como visto, não se consegue negar a hipótese nula de que os dados vieram de uma distribuição normal, o que indica grande possibilidade de que os dados sejam normais. Pode-se, portanto, realizar um teste pareado com as médias dos dados obtidos a cada instância, usando teste t-student.

```{r teste_t, echo=T, eval=T}
result <- wilcox.test(difs, alternative='two.sided', conf.level=0.95)

print(result)
```

Os resultados obtidos pelo teste, portanto, foram:

  - Graus de Liberdade = 44
  - p-valor = 5.684 e-14

#### Teste de Hipótese

### Discussão para Melhoria do Experimento 


## Conclusões


## Referências

---
references:
- id: NyTimes
  title: How Often Is B.M.I. Misleading? 
  URL: https://www.nytimes.com/interactive/projects/cp/summer-of-science-2015/latest/how-often-is-bmi-misleading
  issued:
    year: 2015
    
- id: Science
  title: The Health Risk of Obesity—Better Metrics Imperative
  URL: https://science.sciencemag.org/content/341/6148/856.summary
  issued:
    year: 2013
  
- id: Montgomery2012
  title: Estatística Aplicada e Probabilidade para Engenheiros
  author:
  - family: Montgomery
    given: Douglas
  - family: Runger
    given: George
  publisher: LTC
  type: book
  issued:
    year: 2012
    
- id: Ministerio
  title: IMC em Adultos
  author:
  - family: Ministério da Saúde
    given: 
  URL: 'http://portalms.saude.gov.br/component/content/article/804-imc/40509-imc-em-adultos'
  issued:
    year: 2017
---
